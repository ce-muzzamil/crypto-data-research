{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import *\n",
    "from neural_network import *\n",
    "import time\n",
    "import json\n",
    "from dataset import Dataset\n",
    "from rise_and_fall import *\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy as sci\n",
    "np.set_printoptions(precision=3, linewidth=2*75, suppress=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOT FUNTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frame(f: pd.DataFrame, mxis=[], mnis=[], mark=None):\n",
    "    ps = f[\"meanp\"].to_numpy()\n",
    "    mn = ps.min()\n",
    "    mx = ps.max()\n",
    "    plt.plot(ps)\n",
    "    if len(mxis) > 0:\n",
    "        plt.vlines(x=mxis, ymin=mn, ymax=mx, colors='green',)\n",
    "    elif 'mxis' in f.columns:\n",
    "        plt.vlines(x=f.index[f['mxis'] > 0], ymin=mn, ymax=mx, colors='green',)\n",
    "    if len(mnis) > 0:\n",
    "        plt.vlines(x=mnis, ymin=mn, ymax=mx, colors='red',)\n",
    "    elif 'mnis' in f.columns:\n",
    "        plt.vlines(x=f.index[f['mnis'] > 0], ymin=mn, ymax=mx, colors='red',)\n",
    "    if mark is not None:\n",
    "        plt.vlines(x=[mark], ymin=mn, ymax=mx, colors='blue',)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def unique(xs):\n",
    "    ys = []\n",
    "    for x in xs:\n",
    "        if x in ys:\n",
    "            continue\n",
    "        ys.append(x)\n",
    "    return ys\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVING DATASETS IN NPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Dataset()\n",
    "if __name__ == '__main__':\n",
    "    trx1, trothers = db.get_data_set(\n",
    "        batch_size=2**17, max_procs=10, single_process_size=2**10, buy=True, validation=False, test=False)\n",
    "\n",
    "    vlx1, vlothers = db.get_data_set(\n",
    "        batch_size=2**12, max_procs=10, single_process_size=2**8, buy=True, validation=True, test=False)\n",
    "\n",
    "    tsx1, tsothers = db.get_data_set(\n",
    "        batch_size=2**13, max_procs=10, single_process_size=2**10, buy=True, validation=False, test=True)\n",
    "\n",
    "\n",
    "\n",
    "np.save('database/trx1.npy', trx1)\n",
    "trx2, try1, try2, try3 = trothers\n",
    "np.save('database/trx2.npy', trx2)\n",
    "np.save('database/try1.npy', try1)\n",
    "np.save('database/try2.npy', try2)\n",
    "np.save('database/try3.npy', try3)\n",
    "\n",
    "np.save('database/vlx1.npy', vlx1)\n",
    "vlx2, vly1, vly2, vly3 = vlothers\n",
    "np.save('database/vlx2.npy', vlx2)\n",
    "np.save('database/vly1.npy', vly1)\n",
    "np.save('database/vly2.npy', vly2)\n",
    "np.save('database/vly3.npy', vly3)\n",
    "\n",
    "np.save('database/tsx1.npy', tsx1)\n",
    "tsx2, tsy1, tsy2, tsy3 = tsothers\n",
    "np.save('database/tsx2.npy', tsx2)\n",
    "np.save('database/tsy1.npy', tsy1)\n",
    "np.save('database/tsy2.npy', tsy2)\n",
    "np.save('database/tsy3.npy', tsy3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mx1 = trx1.max(axis=(0,1))\n",
    "# mx2 = vlx1.max(axis=(0,1))\n",
    "# mx =  np.array([mx1, mx1])\n",
    "# mx = mx.max(axis=0).tolist()\n",
    "# with open('norm.json', 'w') as file:\n",
    "#     json.dump(mx, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RETRIVING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dsx_name = 'vlx'\n",
    "# dsy_name = 'vly'\n",
    "\n",
    "# ds = np.load(f'database/{dsx_name}.npy', mmap_mode='r')\n",
    "# indicies = np.random.choice(ds.shape[0], (2**10,))\n",
    "# x = ds[indicies]\n",
    "# del ds\n",
    "# print(x.shape)\n",
    "\n",
    "# ds = np.load(f'database/{dsy_name}.npy', mmap_mode='r')\n",
    "# y = ds.T[indicies]\n",
    "# y = y.T\n",
    "# del ds\n",
    "# print(y.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRETRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noramlize(itter):\n",
    "    with open('norm.json', 'r') as file:\n",
    "        norm = json.load(file)\n",
    "    norm = np.array(norm)\n",
    "    nitter = [\n",
    "        itter[0]/norm,\n",
    "        itter[1]/(288.0*7.0),\n",
    "        itter[2]/288.0,\n",
    "        itter[3]/288.0,\n",
    "        itter[4]/norm[2]\n",
    "    ]\n",
    "    return nitter\n",
    "\n",
    "training = get_data('trx1', 'trx2', 'try1', 'try2', 'try3')\n",
    "validation = get_data('vlx1', 'vlx2', 'vly1', 'vly2', 'vly3')\n",
    "testing = get_data('tsx1', 'tsx2', 'tsy1', 'tsy2', 'tsy3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = noramlize(training)\n",
    "validation = noramlize(validation)\n",
    "testing = noramlize(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "train_bp_model(inputs=training[:2], outputs=training[2:], validation_data=(\n",
    "    validation[:2], validation[2:]), epochs=50, verbose=1, lr=lr, mini_batch_size=, patience=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-6\n",
    "train_bp_model(inputs=training[:2], outputs=training[2:], validation_data=(\n",
    "    validation[:2], validation[2:]), epochs=500, verbose=1, lr=lr, mini_batch_size=32, patience=15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL TESTING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_bp_model(1e-3)\n",
    "plot_model(model, to_file='model_plot.png',\n",
    "           show_shapes=True, show_layer_names=True)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([64*np.log(i+1) for i in range(126)])\n",
    "plt.plot([i**2.5 for i in range(10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = buy_predictor()\n",
    "# plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "# model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19d1d53a962d236aa061289c2ac16dc8e6d9648c89fe79f459ae9a3493bc67b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
